{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "split-aluminum",
      "metadata": {
        "id": "split-aluminum",
        "papermill": {
          "duration": 0.048394,
          "end_time": "2021-04-15T21:06:39.560571",
          "exception": false,
          "start_time": "2021-04-15T21:06:39.512177",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# LAB | Extractive Question Answering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "prospective-turner",
      "metadata": {
        "id": "prospective-turner",
        "papermill": {
          "duration": 0.045573,
          "end_time": "2021-04-15T21:06:39.651272",
          "exception": false,
          "start_time": "2021-04-15T21:06:39.605699",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "This notebook demonstrates how Pinecone helps you build an extractive question-answering application. To build an extractive question-answering system, we need three main components:\n",
        "\n",
        "- A vector index to store and run semantic search\n",
        "- A retriever model for embedding context passages\n",
        "- A reader model to extract answers\n",
        "\n",
        "We will use the SQuAD dataset, which consists of **questions** and **context** paragraphs containing question **answers**. We generate embeddings for the context passages using the retriever, index them in the vector database, and query with semantic search to retrieve the top k most relevant contexts containing potential answers to our question. We then use the reader model to extract the answers from the returned contexts."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oC3GG-dWkZJ6",
      "metadata": {
        "id": "oC3GG-dWkZJ6"
      },
      "source": [
        "Let's get started by installing the packages needed for notebook to run:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "740a3cf7-830c-4f1d-bf8d-90d18f908a99",
      "metadata": {
        "id": "740a3cf7-830c-4f1d-bf8d-90d18f908a99"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# from dotenv import load_dotenv, find_dotenv\n",
        "# _ = load_dotenv(find_dotenv())\n",
        "\n",
        "# OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')\n",
        "# PINECONE_API_KEY= os.getenv('PINECONE_API_KEY')\n",
        "\n",
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "PINECONE_API_KEY = userdata.get('PINECONE_API_KEY')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "terminal-export",
      "metadata": {
        "id": "terminal-export",
        "papermill": {
          "duration": 0.044413,
          "end_time": "2021-04-15T21:06:39.741951",
          "exception": false,
          "start_time": "2021-04-15T21:06:39.697538",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "expressed-executive",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-15T21:06:39.845309Z",
          "iopub.status.busy": "2021-04-15T21:06:39.842494Z",
          "iopub.status.idle": "2021-04-15T21:08:22.163939Z",
          "shell.execute_reply": "2021-04-15T21:08:22.164616Z"
        },
        "id": "expressed-executive",
        "papermill": {
          "duration": 102.376674,
          "end_time": "2021-04-15T21:08:22.165052",
          "exception": false,
          "start_time": "2021-04-15T21:06:39.788378",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "!pip install -qU datasets pinecone-client sentence-transformers torch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29ad3840",
      "metadata": {
        "id": "29ad3840"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hgIieQukgagu",
      "metadata": {
        "id": "hgIieQukgagu"
      },
      "source": [
        "Now let's load the SQUAD dataset from the HuggingFace Model Hub. We load the dataset into a pandas dataframe and filter the title, question, and context columns, and we drop any duplicate context passages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "J250IJeh7NIb",
      "metadata": {
        "id": "J250IJeh7NIb"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# load the squad dataset into a pandas dataframe\n",
        "df = load_dataset(\"squad\", split=\"train\").to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "FcmeNO97dHDO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "FcmeNO97dHDO",
        "outputId": "1f1a26db-ffdc-40eb-daca-63c46def5e94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       title  \\\n",
              "0   University_of_Notre_Dame   \n",
              "5   University_of_Notre_Dame   \n",
              "10  University_of_Notre_Dame   \n",
              "15  University_of_Notre_Dame   \n",
              "20  University_of_Notre_Dame   \n",
              "\n",
              "                                              context  \n",
              "0   Architecturally, the school has a Catholic cha...  \n",
              "5   As at most other universities, Notre Dame's st...  \n",
              "10  The university is the major seat of the Congre...  \n",
              "15  The College of Engineering was established in ...  \n",
              "20  All of Notre Dame's undergraduate students are...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de29950e-752f-40e0-b98f-2fe48cb364df\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>As at most other universities, Notre Dame's st...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>The university is the major seat of the Congre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>The College of Engineering was established in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>All of Notre Dame's undergraduate students are...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de29950e-752f-40e0-b98f-2fe48cb364df')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-de29950e-752f-40e0-b98f-2fe48cb364df button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-de29950e-752f-40e0-b98f-2fe48cb364df');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b94aa9a1-aa6f-4bc5-8d96-aa91233ecef9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b94aa9a1-aa6f-4bc5-8d96-aa91233ecef9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b94aa9a1-aa6f-4bc5-8d96-aa91233ecef9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 18891,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 442,\n        \"samples\": [\n          \"Dominican_Order\",\n          \"Brigham_Young_University\",\n          \"Matter\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 18891,\n        \"samples\": [\n          \"More commonly, in cases where there are three or more parties, no one party is likely to gain power alone, and parties work with each other to form coalition governments. This has been an emerging trend in the politics of the Republic of Ireland since the 1980s and is almost always the case in Germany on national and state level, and in most constituencies at the communal level. Furthermore, since the forming of the Republic of Iceland there has never been a government not led by a coalition (usually of the Independence Party and one other (often the Social Democratic Alliance). A similar situation exists in the Republic of Ireland; since 1989, no one party has held power on its own. Since then, numerous coalition governments have been formed. These coalitions have been exclusively led by one of either Fianna F\\u00e1il or Fine Gael. Political change is often easier with a coalition government than in one-party or two-party dominant systems.[dubious \\u2013 discuss] If factions in a two-party system are in fundamental disagreement on policy goals, or even principles, they can be slow to make policy changes, which appears to be the case now in the U.S. with power split between Democrats and Republicans. Still coalition governments struggle, sometimes for years, to change policy and often fail altogether, post World War II France and Italy being prime examples. When one party in a two-party system controls all elective branches, however, policy changes can be both swift and significant. Democrats Woodrow Wilson, Franklin Roosevelt and Lyndon Johnson were beneficiaries of such fortuitous circumstances, as were Republicans as far removed in time as Abraham Lincoln and Ronald Reagan. Barack Obama briefly had such an advantage between 2009 and 2011.\",\n          \"There has been some concern over the potential adverse environmental and ecosystem effects caused by the influx of visitors. Some environmentalists and scientists have made a call for stricter regulations for ships and a tourism quota. The primary response by Antarctic Treaty Parties has been to develop, through their Committee for Environmental Protection and in partnership with IAATO, \\\"site use guidelines\\\" setting landing limits and closed or restricted zones on the more frequently visited sites. Antarctic sightseeing flights (which did not land) operated out of Australia and New Zealand until the fatal crash of Air New Zealand Flight 901 in 1979 on Mount Erebus, which killed all 257 aboard. Qantas resumed commercial overflights to Antarctica from Australia in the mid-1990s.\",\n          \"After World War II, the Guam Organic Act of 1950 established Guam as an unincorporated organized territory of the United States, provided for the structure of the island's civilian government, and granted the people U.S. citizenship. The Governor of Guam was federally appointed until 1968, when the Guam Elective Governor Act provided for the office's popular election.:242 Since Guam is not a U.S. state, U.S. citizens residing on Guam are not allowed to vote for president and their congressional representative is a non-voting member.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "# select only title and context column\n",
        "df = df[['title', 'context']].copy()\n",
        "# drop rows containing duplicate context passages\n",
        "df.drop_duplicates(subset='context', keep='first', inplace=True)\n",
        "df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57bbcb57",
      "metadata": {
        "id": "57bbcb57"
      },
      "source": [
        "# Initialize Pinecone Index"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e24d904c",
      "metadata": {
        "id": "e24d904c"
      },
      "source": [
        "The Pinecone index stores vector representations of our context passages which we can retrieve using another vector (query vector). We first need to initialize our connection to Pinecone to create our vector index. For this, we need a free [API key](\"https://app.pinecone.io/\"), and then we initialize the connection like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "092d1e71",
      "metadata": {
        "id": "092d1e71"
      },
      "outputs": [],
      "source": [
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "spec = ServerlessSpec(\n",
        "    cloud=\"aws\", region=\"us-east-1\"\n",
        ")\n",
        "\n",
        "# connect to pinecone environment\n",
        "pc = Pinecone(\n",
        "    api_key = PINECONE_API_KEY,\n",
        "    environment='us-east-1'  # find next to API key in console\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58028e12",
      "metadata": {
        "id": "58028e12"
      },
      "source": [
        "Now we create a new index called \"question-answering\" â€” we can name the index anything we want. We specify the metric type as \"cosine\" and dimension as 384 because the retriever we use to generate context embeddings is optimized for cosine similarity and outputs 384-dimension vectors."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Pinecone API Key: {PINECONE_API_KEY}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwJPdtnkIDub",
        "outputId": "fd9f87fb-bae1-4afa-84f4-9bd68b17e837"
      },
      "id": "LwJPdtnkIDub",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pinecone API Key: pcsk_3MGSc1_Qv7t6hxpf3RACW3bjqBsd3ZPgrT523vTeRsBjt61Wcoowpso4hJs2564s7Sq9VS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "b3206184",
      "metadata": {
        "id": "b3206184"
      },
      "outputs": [],
      "source": [
        "index_name = \"question-answering\"\n",
        "\n",
        "# check if the extractive-question-answering index exists\n",
        "if index_name not in pc.list_indexes().names():\n",
        "    # create the index if it does not exist\n",
        "\n",
        "     pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=384,\n",
        "        metric=\"cosine\",\n",
        "        spec=spec\n",
        "        )\n",
        "# connect to extractive-question-answering index we created\n",
        "index = pc.Index(index_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e84a3e5",
      "metadata": {
        "id": "6e84a3e5"
      },
      "source": [
        "# Initialize Retriever"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oZzhGS1Lpj0g",
      "metadata": {
        "id": "oZzhGS1Lpj0g"
      },
      "source": [
        "Next, we need to initialize our retriever. The retriever will mainly do two things:\n",
        "\n",
        "- Generate embeddings for all context passages (context vectors/embeddings)\n",
        "- Generate embeddings for our questions (query vector/embedding)\n",
        "\n",
        "The retriever will generate embeddings in a way that the questions and context passages containing answers to our questions are nearby in the vector space. We can use cosine similarity to calculate the similarity between the query and context embeddings to find the context passages that contain potential answers to our question.\n",
        "\n",
        "We will use a SentenceTransformer model named ``multi-qa-MiniLM-L6-cos-v1`` designed for semantic search and trained on 215M (question, answer) pairs from diverse sources as our retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "31a85bb3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31a85bb3",
        "outputId": "e2cefc45-81b5-4aa5-eefc-124034b04d4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentenceTransformer(\n",
              "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n",
              "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
              "  (2): Normalize()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# set device to GPU if available\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# load the retriever model from huggingface model hub\n",
        "retriever = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1').to(device) #use the 'multi-qa-MiniLM-L6-cos-v1' model from HuggingFace to build the retriever\n",
        "retriever"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8aaad0a2",
      "metadata": {
        "id": "8aaad0a2"
      },
      "source": [
        "# Generate Embeddings and Upsert"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Hgy7AagJtO_p",
      "metadata": {
        "id": "Hgy7AagJtO_p"
      },
      "source": [
        "Next, we need to generate embeddings for the context passages. We will do this in batches to help us more quickly generate embeddings and upload them to the Pinecone index. When passing the documents to Pinecone, we need an id (a unique value), context embedding, and metadata for each document representing context passages in the dataset. The metadata is a dictionary containing data relevant to our embeddings, such as the article title, context passage, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "a17824ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "0800cbe05a0c4706807a86a980d74328",
            "31ec4a8e23d046938b3540529bb08819",
            "265143eb2fdb445d9b1e73ea32629e6b",
            "8741f5a0d1bf4be18661467a35a05318",
            "3314427f87c34d31875440e2161b4374",
            "9b1f8260cf6f48879ca907c3e698af00",
            "7469e891a949400198ab15dfad07659e",
            "f143fd9a928948029f62db776db3b2ee",
            "0b8499c75f194c8f9420dafd82d971e7",
            "f27e96a08df04c21b7c686406c4f6a51",
            "d7679caf5339438bae817cf1a6327b28"
          ]
        },
        "id": "a17824ef",
        "outputId": "5cb2e420-bfd8-4158-f1b8-0f37e7f5f708",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0800cbe05a0c4706807a86a980d74328",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/296 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'dimension': 384,\n",
            " 'index_fullness': 0.0,\n",
            " 'namespaces': {'': {'vector_count': 19840}},\n",
            " 'total_vector_count': 19840}\n"
          ]
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "# we will use batches of 64\n",
        "batch_size = 64\n",
        "\n",
        "for i in tqdm(range(0, len(df), batch_size)):\n",
        "    # find end of batch\n",
        "    i_end = min(i + batch_size, len(df)) #Fixed: Indentation corrected to align with the loop\n",
        "\n",
        "    # extract batch\n",
        "    batch = df.iloc[i:i_end]\n",
        "    # generate embeddings for batch\n",
        "    embeddings = retriever.encode(batch['context'].tolist()).tolist()\n",
        "    # get metadata\n",
        "    meta = batch.to_dict(orient='records')\n",
        "    #create unique IDS\n",
        "    ids = [f\"id-{i}\" for i in range(i, i_end)]\n",
        "    # add all to upsert list\n",
        "    to_upsert = list(zip(ids, embeddings, meta))\n",
        "    # upsert/insert these records to pinecone\n",
        "    index.upsert(vectors=to_upsert)\n",
        "\n",
        "# check that we have all vectors in index\n",
        "print(index.describe_index_stats())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YFyBYafuJ0y0",
      "metadata": {
        "id": "YFyBYafuJ0y0"
      },
      "source": [
        "# Initialize Reader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HgdiLCz5ynOk",
      "metadata": {
        "id": "HgdiLCz5ynOk"
      },
      "source": [
        "We use the `deepset/electra-base-squad2` model from the HuggingFace model hub as our reader model. We load this model into a \"question-answering\" pipeline from HuggingFace transformers and feed it our questions and context passages individually. The model gives a prediction for each context we pass through the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "hg9XTDkIJzH_",
      "metadata": {
        "id": "hg9XTDkIJzH_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cc24941-722f-4240-80b3-55419c65bf22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<transformers.pipelines.question_answering.QuestionAnsweringPipeline at 0x7958051ca050>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "model_name = 'deepset/electra-base-squad2'\n",
        "# load the reader model into a question-answering pipeline\n",
        "reader = pipeline(tokenizer=model_name, model=model_name, task='question-answering', device=device)\n",
        "reader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e14d89d6",
      "metadata": {
        "id": "e14d89d6"
      },
      "source": [
        "Now all the components we need are ready. Let's write some helper functions to execute our queries. The `get_context` function retrieves the context embeddings containing answers to our question from the Pinecone index, and the `extract_answer` function extracts the answers from these context passages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "lyYaY3QEQiHZ",
      "metadata": {
        "id": "lyYaY3QEQiHZ"
      },
      "outputs": [],
      "source": [
        "# gets context passages from the pinecone index\n",
        "def get_context(question, top_k):\n",
        "    # generate embeddings for the question\n",
        "    xq = retriever.encode([question]).tolist()\n",
        "\n",
        "    # Query Pinecone\n",
        "    # Fixed: Pass xq as a keyword argument named 'vector'\n",
        "    results = index.query(vector=xq, top_k=top_k, include_metadata=True)\n",
        "\n",
        "    # search pinecone index for context passage with the answer\n",
        "    xc = index.query(vector=xq, top_k=top_k, include_metadata=True)\n",
        "    # extract the context passage from pinecone search result\n",
        "    c = [result['metadata']['context'] for result in results['matches']]\n",
        "    return c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "Dc9VYOiUQA7B",
      "metadata": {
        "id": "Dc9VYOiUQA7B"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "# extracts answer from the context passage\n",
        "def extract_answer(question, context):\n",
        "    results = []\n",
        "    for c in context:\n",
        "        # feed the reader the question and contexts to extract answers\n",
        "        answer = reader(question=question, context=c)\n",
        "        # add the context to answer dict for printing both together\n",
        "        answer[\"context\"] = c\n",
        "        results.append(answer)\n",
        "    # sort the result based on the score from reader model\n",
        "    sorted_result = pprint(sorted(results, key=lambda x: x['score'], reverse=True))\n",
        "    return sorted_result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extract_answer(question, context)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXetT_-9RnS4",
        "outputId": "035b19c3-2f21-4230-f3c6-8f1a355974f0"
      },
      "id": "IXetT_-9RnS4",
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'answer': '723',\n",
            "  'context': 'The first step was witnessed by at least one-fifth of the '\n",
            "             'population of Earth, or about 723 million people. His first '\n",
            "             \"words when he stepped off the LM's landing footpad were, \"\n",
            "             '\"That\\'s one small step for [a] man, one giant leap for '\n",
            "             'mankind.\" Aldrin joined him on the surface almost 20 minutes '\n",
            "             'later. Altogether, they spent just under two and one-quarter '\n",
            "             'hours outside their craft. The next day, they performed the '\n",
            "             'first launch from another celestial body, and rendezvoused back '\n",
            "             'with Columbia.',\n",
            "  'end': 91,\n",
            "  'score': 2.2161131707932463e-13,\n",
            "  'start': 88},\n",
            " {'answer': '9:56 pm CDT July 20',\n",
            "  'context': 'The trip to the Moon took just over three days. After achieving '\n",
            "             'orbit, Armstrong and Aldrin transferred into the Lunar Module, '\n",
            "             'named Eagle, and after a landing gear inspection by Collins '\n",
            "             'remaining in the Command/Service Module Columbia, began their '\n",
            "             'descent. After overcoming several computer overload alarms '\n",
            "             'caused by an antenna switch left in the wrong position, and a '\n",
            "             'slight downrange error, Armstrong took over manual flight '\n",
            "             'control at about 180 meters (590 ft), and guided the Lunar '\n",
            "             'Module to a safe landing spot at 20:18:04 UTC, July 20, 1969 '\n",
            "             '(3:17:04 pm CDT). The first humans on the Moon would wait '\n",
            "             'another six hours before they ventured out of their craft. At '\n",
            "             '02:56 UTC, July 21 (9:56 pm CDT July 20), Armstrong became the '\n",
            "             'first human to set foot on the Moon.',\n",
            "  'end': 707,\n",
            "  'score': 9.49398911809056e-14,\n",
            "  'start': 688},\n",
            " {'answer': 'Apollo 8',\n",
            "  'context': 'On December 21, 1968, Frank Borman, James Lovell, and William '\n",
            "             'Anders became the first humans to ride the Saturn V rocket into '\n",
            "             'space on Apollo 8. They also became the first to leave low-Earth '\n",
            "             'orbit and go to another celestial body, and entered lunar orbit '\n",
            "             'on December 24. They made ten orbits in twenty hours, and '\n",
            "             'transmitted one of the most watched TV broadcasts in history, '\n",
            "             'with their Christmas Eve program from lunar orbit, that '\n",
            "             'concluded with a reading from the biblical Book of Genesis. Two '\n",
            "             'and a half hours after the broadcast, they fired their engine to '\n",
            "             'perform the first trans-Earth injection to leave lunar orbit and '\n",
            "             'return to the Earth. Apollo 8 safely landed in the Pacific ocean '\n",
            "             \"on December 27, in NASA's first dawn splashdown and recovery.\",\n",
            "  'end': 654,\n",
            "  'score': 7.472366096109712e-14,\n",
            "  'start': 646}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "5E3a3dkJ5ZQD",
      "metadata": {
        "id": "5E3a3dkJ5ZQD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beffa316-28b7-4a18-a2ef-96e7664c8305"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Egypt was producing 691,000 bbl/d of oil and 2,141.05 Tcf of natural gas (in 2013), which makes Egypt as the largest oil producer not member of the Organization of the Petroleum Exporting Countries (OPEC) and the second-largest dry natural gas producer in Africa. In 2013, Egypt was the largest consumer of oil and natural gas in Africa, as more than 20% of total oil consumption and more than 40% of total dry natural gas consumption in Africa. Also, Egypt possesses the largest oil refinery capacity in Africa 726,000 bbl/d (in 2012). Egypt is currently planning to build its first nuclear power plant in El Dabaa city, northern Egypt.']"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "question = \"How much oil is Egypt producing in a day?\"\n",
        "context = get_context(question, top_k = 1)\n",
        "context"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "heKNVbWQ_LtC",
      "metadata": {
        "id": "heKNVbWQ_LtC"
      },
      "source": [
        "As we can see, the retiever is working fine and gets us the context passage that contains the answer to our question. Now let's use the reader to extract the exact answer from the context passage."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Question: \", question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BxknAo8zbaN",
        "outputId": "539f0bcd-9b8c-4910-9564-23f20226af25"
      },
      "id": "0BxknAo8zbaN",
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question:  How much oil is Egypt producing in a day?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkQgya9k9UXY",
        "outputId": "72546605-9eb5-4c90-b4e2-0b589b4a875a"
      },
      "id": "MkQgya9k9UXY",
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Egypt was producing 691,000 bbl/d of oil and 2,141.05 Tcf of natural gas (in 2013), which makes Egypt as the largest oil producer not member of the Organization of the Petroleum Exporting Countries (OPEC) and the second-largest dry natural gas producer in Africa. In 2013, Egypt was the largest consumer of oil and natural gas in Africa, as more than 20% of total oil consumption and more than 40% of total dry natural gas consumption in Africa. Also, Egypt possesses the largest oil refinery capacity in Africa 726,000 bbl/d (in 2012). Egypt is currently planning to build its first nuclear power plant in El Dabaa city, northern Egypt.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "DQ4GWdbMSjPl",
      "metadata": {
        "id": "DQ4GWdbMSjPl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b161ff43-91ed-4aea-f221-bc04d6ec799f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'answer': '691,000 bbl/d',\n",
            "  'context': 'Egypt was producing 691,000 bbl/d of oil and 2,141.05 Tcf of '\n",
            "             'natural gas (in 2013), which makes Egypt as the largest oil '\n",
            "             'producer not member of the Organization of the Petroleum '\n",
            "             'Exporting Countries (OPEC) and the second-largest dry natural '\n",
            "             'gas producer in Africa. In 2013, Egypt was the largest consumer '\n",
            "             'of oil and natural gas in Africa, as more than 20% of total oil '\n",
            "             'consumption and more than 40% of total dry natural gas '\n",
            "             'consumption in Africa. Also, Egypt possesses the largest oil '\n",
            "             'refinery capacity in Africa 726,000 bbl/d (in 2012). Egypt is '\n",
            "             'currently planning to build its first nuclear power plant in El '\n",
            "             'Dabaa city, northern Egypt.',\n",
            "  'end': 33,\n",
            "  'score': 0.9999852180480957,\n",
            "  'start': 20}]\n"
          ]
        }
      ],
      "source": [
        "extract_answer(question, context)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fMD_ABuDAyhN",
      "metadata": {
        "id": "fMD_ABuDAyhN"
      },
      "source": [
        "The reader model predicted with 99% accuracy the correct answer *691,000 bbl/d* as seen from the context passage. Let's run few more queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "_4NRgV4mGWoj",
      "metadata": {
        "id": "_4NRgV4mGWoj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31de1422-b7c5-4d02-da33-ada8e275d677"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'answer': 'Hurley and Chen',\n",
            "  'context': 'According to a story that has often been repeated in the media, '\n",
            "             'Hurley and Chen developed the idea for YouTube during the early '\n",
            "             'months of 2005, after they had experienced difficulty sharing '\n",
            "             \"videos that had been shot at a dinner party at Chen's apartment \"\n",
            "             'in San Francisco. Karim did not attend the party and denied that '\n",
            "             'it had occurred, but Chen commented that the idea that YouTube '\n",
            "             'was founded after a dinner party \"was probably very strengthened '\n",
            "             'by marketing ideas around creating a story that was very '\n",
            "             'digestible\".',\n",
            "  'end': 79,\n",
            "  'score': 0.9999276399612427,\n",
            "  'start': 64}]\n"
          ]
        }
      ],
      "source": [
        "question = \"What are the first names of the men that invented youtube?\"\n",
        "context = get_context(question, top_k=1)\n",
        "extract_answer(question, context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "juXlctWgJgMF",
      "metadata": {
        "id": "juXlctWgJgMF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7488b07-f10d-4433-bee8-1ed52fbe91c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'answer': 'his theories of special relativity and general relativity',\n",
            "  'context': 'Albert Einstein is known for his theories of special relativity '\n",
            "             'and general relativity. He also made important contributions to '\n",
            "             'statistical mechanics, especially his mathematical treatment of '\n",
            "             'Brownian motion, his resolution of the paradox of specific '\n",
            "             'heats, and his connection of fluctuations and dissipation. '\n",
            "             'Despite his reservations about its interpretation, Einstein also '\n",
            "             'made contributions to quantum mechanics and, indirectly, quantum '\n",
            "             'field theory, primarily through his theoretical studies of the '\n",
            "             'photon.',\n",
            "  'end': 86,\n",
            "  'score': 0.9500371217727661,\n",
            "  'start': 29}]\n"
          ]
        }
      ],
      "source": [
        "question = \"What is Albert Eistein famous for?\"\n",
        "context = get_context(question, top_k=1)\n",
        "extract_answer(question, context)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OhCgeny_BVno",
      "metadata": {
        "id": "OhCgeny_BVno"
      },
      "source": [
        "Let's run another question. This time for top 3 context passages from the retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "iXACn71xmett",
      "metadata": {
        "id": "iXACn71xmett",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "450b206d-3e03-424c-e0e9-38b031e4342a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'answer': 'Armstrong',\n",
            "  'context': 'The trip to the Moon took just over three days. After achieving '\n",
            "             'orbit, Armstrong and Aldrin transferred into the Lunar Module, '\n",
            "             'named Eagle, and after a landing gear inspection by Collins '\n",
            "             'remaining in the Command/Service Module Columbia, began their '\n",
            "             'descent. After overcoming several computer overload alarms '\n",
            "             'caused by an antenna switch left in the wrong position, and a '\n",
            "             'slight downrange error, Armstrong took over manual flight '\n",
            "             'control at about 180 meters (590 ft), and guided the Lunar '\n",
            "             'Module to a safe landing spot at 20:18:04 UTC, July 20, 1969 '\n",
            "             '(3:17:04 pm CDT). The first humans on the Moon would wait '\n",
            "             'another six hours before they ventured out of their craft. At '\n",
            "             '02:56 UTC, July 21 (9:56 pm CDT July 20), Armstrong became the '\n",
            "             'first human to set foot on the Moon.',\n",
            "  'end': 80,\n",
            "  'score': 0.9998037815093994,\n",
            "  'start': 71},\n",
            " {'answer': 'Aldrin',\n",
            "  'context': 'The first step was witnessed by at least one-fifth of the '\n",
            "             'population of Earth, or about 723 million people. His first '\n",
            "             \"words when he stepped off the LM's landing footpad were, \"\n",
            "             '\"That\\'s one small step for [a] man, one giant leap for '\n",
            "             'mankind.\" Aldrin joined him on the surface almost 20 minutes '\n",
            "             'later. Altogether, they spent just under two and one-quarter '\n",
            "             'hours outside their craft. The next day, they performed the '\n",
            "             'first launch from another celestial body, and rendezvoused back '\n",
            "             'with Columbia.',\n",
            "  'end': 246,\n",
            "  'score': 0.695867121219635,\n",
            "  'start': 240},\n",
            " {'answer': 'Frank Borman',\n",
            "  'context': 'On December 21, 1968, Frank Borman, James Lovell, and William '\n",
            "             'Anders became the first humans to ride the Saturn V rocket into '\n",
            "             'space on Apollo 8. They also became the first to leave low-Earth '\n",
            "             'orbit and go to another celestial body, and entered lunar orbit '\n",
            "             'on December 24. They made ten orbits in twenty hours, and '\n",
            "             'transmitted one of the most watched TV broadcasts in history, '\n",
            "             'with their Christmas Eve program from lunar orbit, that '\n",
            "             'concluded with a reading from the biblical Book of Genesis. Two '\n",
            "             'and a half hours after the broadcast, they fired their engine to '\n",
            "             'perform the first trans-Earth injection to leave lunar orbit and '\n",
            "             'return to the Earth. Apollo 8 safely landed in the Pacific ocean '\n",
            "             \"on December 27, in NASA's first dawn splashdown and recovery.\",\n",
            "  'end': 34,\n",
            "  'score': 0.49246710538864136,\n",
            "  'start': 22}]\n"
          ]
        }
      ],
      "source": [
        "question = \"Who was the first person to step foot on the moon?\"\n",
        "context = get_context(question, top_k=3)\n",
        "extract_answer(question, context)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9oCWHy0tPpV",
      "metadata": {
        "id": "c9oCWHy0tPpV"
      },
      "source": [
        "The result looks pretty good."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "d83f9f55-b099-4280-a12e-1d0192f4f5aa",
      "metadata": {
        "id": "d83f9f55-b099-4280-a12e-1d0192f4f5aa"
      },
      "outputs": [],
      "source": [
        "pc.delete_index(index_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27fecadc-6976-43b2-90e1-788a8633ecc7",
      "metadata": {
        "id": "27fecadc-6976-43b2-90e1-788a8633ecc7"
      },
      "source": [
        "### Add a few more questions. What did you observe?"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "question_answering.ipynb",
      "provenance": []
    },
    "environment": {
      "name": "tf2-gpu.2-3.m65",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m65"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 333.240754,
      "end_time": "2021-04-15T21:12:11.363566",
      "environment_variables": {},
      "exception": null,
      "input_path": "/notebooks/question_answering/question_answering.ipynb",
      "output_path": "/notebooks/tmp/question_answering/question_answering.ipynb",
      "parameters": {},
      "start_time": "2021-04-15T21:06:38.122812",
      "version": "2.3.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "5fe10bf018ef3e697f9035d60bf60847932a12bface18908407fd371fe880db9"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0800cbe05a0c4706807a86a980d74328": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31ec4a8e23d046938b3540529bb08819",
              "IPY_MODEL_265143eb2fdb445d9b1e73ea32629e6b",
              "IPY_MODEL_8741f5a0d1bf4be18661467a35a05318"
            ],
            "layout": "IPY_MODEL_3314427f87c34d31875440e2161b4374"
          }
        },
        "31ec4a8e23d046938b3540529bb08819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b1f8260cf6f48879ca907c3e698af00",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7469e891a949400198ab15dfad07659e",
            "value": "100%"
          }
        },
        "265143eb2fdb445d9b1e73ea32629e6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f143fd9a928948029f62db776db3b2ee",
            "max": 296,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b8499c75f194c8f9420dafd82d971e7",
            "value": 296
          }
        },
        "8741f5a0d1bf4be18661467a35a05318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f27e96a08df04c21b7c686406c4f6a51",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d7679caf5339438bae817cf1a6327b28",
            "value": "â€‡296/296â€‡[02:38&lt;00:00,â€‡â€‡2.37it/s]"
          }
        },
        "3314427f87c34d31875440e2161b4374": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b1f8260cf6f48879ca907c3e698af00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7469e891a949400198ab15dfad07659e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f143fd9a928948029f62db776db3b2ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b8499c75f194c8f9420dafd82d971e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f27e96a08df04c21b7c686406c4f6a51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7679caf5339438bae817cf1a6327b28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}